---
title: "Data Science Methods - Assignment 1"
author:
- "M. Alberti, 2020162"
- "N. Ceschin, 344510" 

date: February 21, 2020
output: pdf_document

---

## Question 1

First we upload all relevant libraries:

```{r results='hide', message=FALSE, warning=FALSE}
library(readxl)
library(ggplot2)
library(ggfortify)
library(dplyr)
library(tidyr)
library(RCurl)
library(ggrepel)
```

Upload dataset:

```{r results='hide', message=FALSE, warning=FALSE}
#setwd("C:/Users/Mr Nobody/Desktop/Uni/EME/Data science Methods/Assignments")
setwd("~/Tilburg/Courses/Data Science Methods/Assignment1/DATA-SCIENCE-ASSIGNMENTS")
data<-read_excel("env_air_emis.xls")
urlRemote<-"https://raw.githubusercontent.com/"
pathGithub<-"AlbertiMarco/DATA-SCIENCE-ASSIGNMENTS/master/EU%20labels.csv"
x <- paste0(urlRemote, pathGithub)
#import country tags to make plots more readable
EU_labels<- read.csv(text = x, header = FALSE ,sep=";") 
rownames(EU_labels)<-EU_labels[[1]]

```

After a quick glimpse of the data we realized that information for the five pollutant are presented in separated consecutive tables, the separation contains some information in the first column and NA cells in the rest. To be sure not to drop NAs in the middle of the dataset, we first proceed to drop all raws containing at least 5 NA values and we assign to *df*: 
```{r results='hide', message=FALSE, warning=FALSE}
dim(data)
df<-data[rowSums(is.na(data))<length(data)-5,]

```

Given the data structure and the subpoints a-c requests, we decided that the optimal approach would be looping over the chunks of data containing information for each pollutant, producing without repeting the code the outputs all in one step. First we create some variables that will be used in the loop: 

```{r results='hide', message=FALSE, warning=FALSE}
#build 'index' for your loop
interval<-c(1,30,59,88,117)               #first row of each datset 
pollutants<-c("ammonia","nmvoc","smallpart","largepart","sulphur")
index<-data.frame(interval,pollutants)

PC1<-data.frame(matrix(ncol=5,nrow=28))   #dataframes to be filled with PC1-2
PC2<-data.frame(matrix(ncol=5,nrow=28))  

```

Then we run the loop that:

1) Selects the chunk of the dataframe corresponding to one pollutant and puts it into shape
2) Runs PCA on the reduced dataframe and produces the plots of the first two PCs
3) Produces a scree plot
4) Computes the Bayesian Informatio Criteria and prints the optimal number of PCs according to this method 
5) Stores plots and loadings for future use

```{r results='hide', message=FALSE, warning=FALSE, plot=FALSE}
mytheme <- theme(plot.title= element_text(face="bold",
  colour = "antiquewhite4",size = (16),hjust = 0.5))     #setting theme for plots

for (i in 1:5){
  #data chunk preparation
  begin<-index[i,1]                        #select the right range to cut main dataset
  end<-index[i,1]+28                       
  dfx<-df[begin:end,] 
  dfx<-as.data.frame(dfx) 
  colnames(dfx)<-dfx[1,]         
  rownames(dfx)<-dfx[,1]
  dfx<-dfx[c(2:29),c(2:29)]                #drop first column and row
  if (sum(mapply(grepl,rownames(EU_labels),rownames(dfx)))==length(dfx)) {
  rownames(dfx)<- EU_labels[[2]] 
    }                                      #substitute name with short labels 
  dfx<-as.data.frame(t(dfx))               #convert factor columns into numeric 
  indx <- sapply(dfx, is.factor)
  dfx[indx] <- lapply(dfx[indx], function(x) as.numeric(as.character(x)))
  
  
  #Principal Component Analysis
  pr.out<-prcomp(dfx, scale=TRUE)
  graph<-autoplot(pr.out,variance_percentage=FALSE,loadings=TRUE,
           loadings.label=TRUE,loadings.label.repel=TRUE,loadings.colour="coral",
           loadings.label.size=3,loadings.label.colour="grey35",scale=0,colour="gold2")+
           ggtitle(paste("The first two PCs for",toString(index[i,2]),"pollutant"))+
           mytheme 
  pve= 100* (pr.out$sdev ^2)/ sum(pr.out$sdev ^2)             #screeplot
  pvedf<-as.data.frame(pve)
  pvedf["PC"]<-c(1:28)
  scree<-ggplot(pvedf, aes(x=factor(PC),y=pve, group=1))+
    geom_point(size =2.25,color="blue")+geom_line(size = 1,color="blue")+
    labs(title="Screeplot", x="Number of principal components", 
    y="Proportion of variance explained")
  
  #compute vector of BIC for first 27 principal components
  BIC<-c(1:27)   
  for (j in 1:27) {
    f<-pr.out$x[,1:j]%*%t(pr.out$rotation[,1:j]) #compute aF in X=aF+e
    res_mat<-scale(dfx)-f                        #compute matrix of residuals
    res_mat_sq<-res_mat*res_mat                 
    if (j==1){
      res<-(sum(res_mat_sq)/(dim(dfx)[1]*dim(dfx)[2]))   
    } else{
    res<-(sum(rowSums(res_mat_sq))/(dim(dfx)[1]*dim(dfx)[2]))   #residuals sum of squares
    }
    k<-j
    BICk<-log(res)+k*(log(28^2))/(28^2) 
    BIC[j]<-BICk                                 #fill BIC vector at each iteration
    }
  min<-min(BIC)
  num_pc<-match(min,BIC)                         #number of PC selected by BIC
  
  
  #save first two PC in separate dataset for point d)
  PC1[i]<-pr.out$x[,1]
  colnames(PC1)[i]<-as.character(index[i,2])
  PC2[i]<-pr.out$x[,2]
  colnames(PC2)[i]<-as.character(index[i,2])
  
  #save relevant objects with their respective name for each pollutant
  assign(paste0("BIC_", index[i,2]), BIC)       #vector of BIC
  assign(paste0("df_", index[i,2]), dfx)        #dataset
  assign(paste0("prcomp_",index[i,2]),pr.out)   #output of prcomp
  assign(paste0("Screeplot_",index[i,2]),scree) #scree plot
  assign(paste0("PC1-PC2_",index[i,2]),graph)   #plot of first two PCs
  assign(paste0("num_pc_", index[i,2]), num_pc) #number of PC selected by BIC
  
  #remove non relevant objects
  rm(dfx)
  rm(BIC)
  rm(pr.out)
  rm(num_pc)
  rm(scree)
}
```
Now to comment on the results we can called the corresponding stored object.

```{r}
print(`PC1-PC2_ammonia`)

```

## d) 
We plot the first 2 principal components for all the five pollutants over the time interval.

Code to produce the plots:

```{r results='hide', message=FALSE, warning=FALSE}
theme2<-theme(axis.text.x = element_text(angle = 45, hjust=1))
PC1["years"]<-c(1990:2017)
PC1<-gather(PC1, `ammonia`, `largepart`, `nmvoc`,`smallpart`, `sulphur`, key = "pollutant", value = "value") #transform data to be plotted
PC1_plot<-ggplot(PC1,aes(x=factor(years),y=value, group=pollutant,color=pollutant))+
  geom_point(size = 2.25) +  geom_line(size = 1) +theme2 +mytheme+
  labs(title = "PC1",x="Years",y="Value")

PC2["years"]<-c(1990:2017)
PC2<-gather(PC2, `ammonia`, `largepart`, `nmvoc`,     
            `smallpart`, `sulphur`, key = "pollutant", value = "value")
PC2_plot<-ggplot(PC2,aes(x=factor(years),y=value, group=pollutant,color=pollutant))+
  geom_point(size = 2.25) +  geom_line(size = 1) +theme2 +mytheme+
  labs(title = "PC2",x="Years",y="Value")
```

Here is the plot of the first principal component over time for the five pollutant in the dataset:

```{r message=FALSE, warning=FALSE}
print(PC1_plot)
```

Here is the same plot for the second principal component:

```{r message=FALSE, warning=FALSE}
print(PC2_plot)
```


## Question 2




## Question 3

a)  $p_1(x)=\frac{Pr(Y=1)Pr(X=x|Y=1)}{\sum_{l=1}^K{Pr(Y=l)Pr(X=x|Y=1)}}$

In this case we have that:

* $\pi_k=Pr(Y=k)$ is prior probability for class k
* $X|Y=k \sim f_k(x)=N(\mu_k,\sigma^2)$ is the distribution of X for each class k

Using the Bayes rule to rewrite:
$$p_{1}(x)=\frac{\pi_1f_1(x)}{\pi_1f_1(x)+\pi_2f_2(x)}$$
In order to ease calculations in the next step, it is convenient to keep implicit the likelihood functions for the moment.

b)  Plugging in the posterior probability of class 1 obtained in the previous point, we obtain:
$$\log\left(\frac{p_1(x)}{1-p_1(x)}\right)=\log\left(\frac{\frac{\pi_1f_1(x)}{\pi_1f_1(x)+\pi_2f_2(x)}}{1-\frac{\pi_1f_1(x)}{\pi_1f_1(x)+\pi_2f_2(x)}}\right)=\log\left(\frac{\pi_1f_1(x)}{\pi_2f_2(x)}\right)$$
We can now explicit the likelihood functions and simplify conveniently
$$\log\left(\frac{p_1(x)}{1-p_1(x)}\right)=\log\left(\frac{\pi_1}{\pi_2}\right)+\log\left(\frac{f_1(X)}{f_2(x)}\right)=\log\left(\frac{\pi_1}{\pi_2}\right)+\log\left(\exp\left((x-\mu_1)^2-(x-\mu_2)^2\right)\right)$$
$$=\log\left(\frac{\pi_1}{\pi_2}\right)-\frac{1}{2\sigma^2}(-2x\mu_1+\mu_{2}^2 +2x\mu_2-\mu_{2}^2)=\left[\log\left(\frac{\pi_1}{\pi_2}\right) + \frac{\mu_{2}^2-\mu_{1}^2}{2\sigma^2}\right]+x\left[\frac{\mu_1+\mu_2}{\sigma^2}\right]=$$
Therefore, 

* $c_0=\log\left(\frac{\pi_1}{\pi_2}\right) + \frac{\mu_{2}^2-\mu_{1}^2}{2\sigma^2}$
* $c_1=\frac{\mu_1+\mu_2}{\sigma^2}$      

c) This derivation helps us appreciating how these two classfication methods are closely related. In particular, the log-odds ratio is linear in $x$ in both cases. In the logit model, the parameters estimated by maximum-likelihood are exactly the intercept and the coefficient on the $x$, while in LDA $c_0$ and $c_1$ are functions on the prior probabilities and of the paramters of the likelihood functions $\mu_1,\mu_2,\sigma^2$. We could conclude that the parameters estimated by the logit model are somehow *reduced forms* of those of LDA.

d) Knowing that the Bayes classifier assigns an observation $X = x$ to the class k for which the posterior probability $P(Y = k|X = x)$ is the largest, we start by calculating the posterior probability of beloning to a generic class:

$$p_k(k)=\frac{Pr(Y=k)Pr(X=x|Y=k)}{\sum_{l=1}^K{Pr(Y=l)Pr(X=x|Y=1)}}=\frac{\pi_kf_k(x)}{\sum_{l=1}^K \pi_lf_l(x)}$$

Therefore, the Bayes classifier assign $X=x$ to class 1 if $p_1(x)>p_2(x)$, that is equivalent to $\frac{p_1(x)}{p_2(x)}>1$. Therefore, we can restate this rule as
$$\frac{p_1(x)}{p_2(x)}=\frac{\frac{\pi_1f_1(x)}{\sum_{l=1}^K \pi_lf_l(x)}}{\frac{\pi_2f_2(x)}{\sum_{l=1}^K \pi_lf_l(x)}}=\frac{\pi_1f_1(x)}{\pi_2f_2(x)}>1$$

By making the density function explicit and taking the logarithm of both numerator and denominator, the first constant term of the density function simplifies and we are left with
$$\frac{-\frac{1}{2}\left(x^T\Sigma^{-1}x-2x^{T}\Sigma^{-1}\mu_1+\mu_1^{T}\Sigma^{-1}\mu_1\right)+\log(\pi_1)}{-\frac{1}{2}\left(x^T\Sigma^{-1}x-2x^{T}\Sigma^{-1}\mu_2+\mu_2^{T}\Sigma^{-1}\mu_2\right)+\log(\pi_2)}>1$$

Which corresponds to 
$$-\frac{1}{2}(x^T\Sigma^{-1}x)+x^{T}\Sigma^{-1}\mu_1-\frac{1}{2}(\mu_1^{T}\Sigma^{-1}\mu_1)+\log(\pi_1)>-\frac{1}{2}(x^T\Sigma^{-1}x)+x^{T}\Sigma^{-1}\mu_2-\frac{1}{2}(\mu_2^{T}\Sigma^{-1}\mu_2)+\log(\pi_2)$$
$$\iff$$
$$x^{T}\Sigma^{-1}\mu_1-\frac{1}{2}(\mu_1^{T}\Sigma^{-1}\mu_1)+\log(\pi_1)>x^{T}\Sigma^{-1}\mu_2-\frac{1}{2}(\mu_2^{T}\Sigma^{-1}\mu_2)+\log(\pi_2)$$

Which corresponds exactly to $\delta_1(x)>\delta_2(x).$





